{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hw_tts.model as model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/bayesian_monster/text2speech1/testing.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/bayesian_monster/text2speech1/testing.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mFastSpeechModel(\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m,\u001b[39m0\u001b[39;49m,\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/text2speech1/hw_tts/model/FastSpeech2/FastSpeechV2.py:165\u001b[0m, in \u001b[0;36mFastSpeechModel.__init__\u001b[0;34m(self, max_seq_len, encoder_n_layer, decoder_n_layer, vocab_size, encoder_dim, encoder_head, encoder_filter_size, decoder_dim, decoder_head, decoder_filter_size, fft_kernel, fft_padding, duration_predictor_filter_size, duration_predictor_kernel_size, pitch_predictor_filter_size, pitch_predictor_kernel_size, energy_predictor_filter_size, energy_predictor_kernel_size, min_pitch, max_pitch, min_energy, max_energy, num_bins, num_mels, PAD, dropout)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, max_seq_len,\n\u001b[1;32m    137\u001b[0m     encoder_n_layer,\n\u001b[1;32m    138\u001b[0m     decoder_n_layer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    161\u001b[0m     dropout\n\u001b[1;32m    162\u001b[0m     ):\n\u001b[1;32m    163\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[0;32m--> 165\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder \u001b[39m=\u001b[39m Encoder(max_seq_len, \n\u001b[1;32m    166\u001b[0m         encoder_n_layer,\n\u001b[1;32m    167\u001b[0m         vocab_size,\n\u001b[1;32m    168\u001b[0m         encoder_dim,\n\u001b[1;32m    169\u001b[0m         encoder_head,\n\u001b[1;32m    170\u001b[0m         encoder_filter_size,\n\u001b[1;32m    171\u001b[0m         fft_kernel,\n\u001b[1;32m    172\u001b[0m         fft_padding,\n\u001b[1;32m    173\u001b[0m         PAD,\n\u001b[1;32m    174\u001b[0m         dropout\n\u001b[1;32m    175\u001b[0m     )\n\u001b[1;32m    176\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength_regulator \u001b[39m=\u001b[39m LengthRegulator(encoder_dim, \n\u001b[1;32m    177\u001b[0m         duration_predictor_filter_size,\n\u001b[1;32m    178\u001b[0m         duration_predictor_kernel_size,\n\u001b[1;32m    179\u001b[0m         dropout\n\u001b[1;32m    180\u001b[0m     )\n\u001b[1;32m    181\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder \u001b[39m=\u001b[39m Decoder(max_seq_len, \n\u001b[1;32m    182\u001b[0m         decoder_n_layer,\n\u001b[1;32m    183\u001b[0m         decoder_dim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    189\u001b[0m         dropout\n\u001b[1;32m    190\u001b[0m     )\n",
      "File \u001b[0;32m~/text2speech1/hw_tts/model/FastSpeech2/FastSpeechV2.py:41\u001b[0m, in \u001b[0;36mEncoder.__init__\u001b[0;34m(self, max_seq_len, encoder_n_layer, vocab_size, encoder_dim, encoder_head, encoder_filter_size, fft_kernel, fft_padding, PAD, dropout)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msrc_word_emb \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mEmbedding(\n\u001b[1;32m     30\u001b[0m     vocab_size,\n\u001b[1;32m     31\u001b[0m     encoder_dim,\n\u001b[1;32m     32\u001b[0m     padding_idx\u001b[39m=\u001b[39mPAD\n\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     35\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_enc \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mEmbedding(\n\u001b[1;32m     36\u001b[0m     n_position,\n\u001b[1;32m     37\u001b[0m     encoder_dim,\n\u001b[1;32m     38\u001b[0m     padding_idx\u001b[39m=\u001b[39mPAD\n\u001b[1;32m     39\u001b[0m )\n\u001b[0;32m---> 41\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_stack \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mModuleList([\n\u001b[1;32m     42\u001b[0m     FFTBlock(encoder_dim, \n\u001b[1;32m     43\u001b[0m              encoder_filter_size,\n\u001b[1;32m     44\u001b[0m              encoder_head,\n\u001b[1;32m     45\u001b[0m              encoder_dim \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m encoder_head,\n\u001b[1;32m     46\u001b[0m              encoder_dim \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m encoder_head,\n\u001b[1;32m     47\u001b[0m              fft_kernel,\n\u001b[1;32m     48\u001b[0m              fft_padding,\n\u001b[1;32m     49\u001b[0m              dropout\u001b[39m=\u001b[39;49mdropout) \u001b[39mfor\u001b[39;49;00m _ \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(n_layers)])\n\u001b[1;32m     50\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mPAD \u001b[39m=\u001b[39m PAD\n",
      "File \u001b[0;32m~/text2speech1/hw_tts/model/FastSpeech2/FastSpeechV2.py:42\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msrc_word_emb \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mEmbedding(\n\u001b[1;32m     30\u001b[0m     vocab_size,\n\u001b[1;32m     31\u001b[0m     encoder_dim,\n\u001b[1;32m     32\u001b[0m     padding_idx\u001b[39m=\u001b[39mPAD\n\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     35\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_enc \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mEmbedding(\n\u001b[1;32m     36\u001b[0m     n_position,\n\u001b[1;32m     37\u001b[0m     encoder_dim,\n\u001b[1;32m     38\u001b[0m     padding_idx\u001b[39m=\u001b[39mPAD\n\u001b[1;32m     39\u001b[0m )\n\u001b[1;32m     41\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_stack \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mModuleList([\n\u001b[0;32m---> 42\u001b[0m     FFTBlock(encoder_dim, \n\u001b[1;32m     43\u001b[0m              encoder_filter_size,\n\u001b[1;32m     44\u001b[0m              encoder_head,\n\u001b[1;32m     45\u001b[0m              encoder_dim \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m encoder_head,\n\u001b[1;32m     46\u001b[0m              encoder_dim \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m encoder_head,\n\u001b[1;32m     47\u001b[0m              fft_kernel,\n\u001b[1;32m     48\u001b[0m              fft_padding,\n\u001b[1;32m     49\u001b[0m              dropout\u001b[39m=\u001b[39;49mdropout) \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_layers)])\n\u001b[1;32m     50\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mPAD \u001b[39m=\u001b[39m PAD\n",
      "File \u001b[0;32m~/text2speech1/hw_tts/model/FastSpeech2/FFT.py:24\u001b[0m, in \u001b[0;36mFFTBlock.__init__\u001b[0;34m(self, d_model, d_inner, n_head, d_k, d_v, fft_kernel, fft_padding, dropout)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m     22\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mslf_attn \u001b[39m=\u001b[39m MultiHeadAttention(\n\u001b[1;32m     23\u001b[0m     n_head, d_model, d_k, d_v, dropout\u001b[39m=\u001b[39mdropout)\n\u001b[0;32m---> 24\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_ffn \u001b[39m=\u001b[39m PositionwiseFeedForward(\n\u001b[1;32m     25\u001b[0m     d_model, d_inner, fft_kernel, fft_padding, dropout\u001b[39m=\u001b[39;49mdropout)\n",
      "File \u001b[0;32m~/text2speech1/hw_tts/model/FastSpeech2/feedforwardlayer.py:14\u001b[0m, in \u001b[0;36mPositionwiseFeedForward.__init__\u001b[0;34m(self, d_in, d_hid, fft_kernel_size, fft_padding, dropout)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m     11\u001b[0m \u001b[39m# Use Conv1D\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39m# position-wise\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mw_1 \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mConv1d(\n\u001b[0;32m---> 14\u001b[0m     d_in, d_hid, kernel_size\u001b[39m=\u001b[39mfft_kernel_size[\u001b[39m0\u001b[39;49m], padding\u001b[39m=\u001b[39mfft_padding[\u001b[39m0\u001b[39m])\n\u001b[1;32m     15\u001b[0m \u001b[39m# position-wise\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mw_2 \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mConv1d(\n\u001b[1;32m     17\u001b[0m     d_hid, d_in, kernel_size\u001b[39m=\u001b[39mfft_kernel_size[\u001b[39m1\u001b[39m], padding\u001b[39m=\u001b[39mfft_padding[\u001b[39m1\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
